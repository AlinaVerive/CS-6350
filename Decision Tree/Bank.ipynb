{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e161a375-ef8f-4972-835c-e3022d2e382a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Heuristic  Max Depth  Train Error  Test Error\n",
      "0   information_gain          1       0.1192      0.1248\n",
      "1   information_gain          2       0.1060      0.1114\n",
      "2   information_gain          3       0.1006      0.1080\n",
      "3   information_gain          4       0.0800      0.1264\n",
      "4   information_gain          5       0.0624      0.1420\n",
      "5   information_gain          6       0.0480      0.1508\n",
      "6   information_gain          7       0.0372      0.1604\n",
      "7   information_gain          8       0.0292      0.1658\n",
      "8   information_gain          9       0.0222      0.1708\n",
      "9   information_gain         10       0.0182      0.1752\n",
      "10  information_gain         11       0.0154      0.1760\n",
      "11  information_gain         12       0.0140      0.1788\n",
      "12  information_gain         13       0.0136      0.1790\n",
      "13  information_gain         14       0.0136      0.1790\n",
      "14  information_gain         15       0.0136      0.1790\n",
      "15  information_gain         16       0.0136      0.1790\n",
      "16    majority_error          1       0.1088      0.1166\n",
      "17    majority_error          2       0.1042      0.1088\n",
      "18    majority_error          3       0.0966      0.1146\n",
      "19    majority_error          4       0.0850      0.1248\n",
      "20    majority_error          5       0.0728      0.1306\n",
      "21    majority_error          6       0.0690      0.1378\n",
      "22    majority_error          7       0.0678      0.1366\n",
      "23    majority_error          8       0.0676      0.1366\n",
      "24    majority_error          9       0.0676      0.1366\n",
      "25    majority_error         10       0.0676      0.1366\n",
      "26    majority_error         11       0.0676      0.1366\n",
      "27    majority_error         12       0.0676      0.1366\n",
      "28    majority_error         13       0.0676      0.1366\n",
      "29    majority_error         14       0.0676      0.1366\n",
      "30    majority_error         15       0.0676      0.1366\n",
      "31    majority_error         16       0.0676      0.1366\n",
      "32        gini_index          1       0.1088      0.1166\n",
      "33        gini_index          2       0.1042      0.1088\n",
      "34        gini_index          3       0.0936      0.1156\n",
      "35        gini_index          4       0.0754      0.1328\n",
      "36        gini_index          5       0.0604      0.1510\n",
      "37        gini_index          6       0.0484      0.1648\n",
      "38        gini_index          7       0.0364      0.1746\n",
      "39        gini_index          8       0.0268      0.1786\n",
      "40        gini_index          9       0.0216      0.1830\n",
      "41        gini_index         10       0.0174      0.1862\n",
      "42        gini_index         11       0.0144      0.1894\n",
      "43        gini_index         12       0.0140      0.1902\n",
      "44        gini_index         13       0.0136      0.1904\n",
      "45        gini_index         14       0.0136      0.1904\n",
      "46        gini_index         15       0.0136      0.1904\n",
      "47        gini_index         16       0.0136      0.1904\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from math import log2\n",
    "\n",
    "# Load the train and test datasets\n",
    "train_data = pd.read_csv('train.csv', header=None)\n",
    "test_data = pd.read_csv('test.csv', header=None)\n",
    "\n",
    "# Assign column names based on the data description\n",
    "columns = ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', \n",
    "               'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'y']\n",
    "train_data.columns = columns\n",
    "test_data.columns = columns\n",
    "\n",
    "# Identify numerical columns\n",
    "numerical_columns = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# Convert numerical columns to binary using the median as the threshold\n",
    "for col in numerical_columns:\n",
    "    median_value = train_data[col].median()\n",
    "    train_data[col] = train_data[col].apply(lambda x: 1 if x > median_value else 0)\n",
    "    test_data[col] = test_data[col].apply(lambda x: 1 if x > median_value else 0)\n",
    "\n",
    "# Adjust the heuristic functions to handle possible empty subsets\n",
    "def entropy(data):\n",
    "    \"\"\"Calculate the entropy for a dataset, handling possible empty subsets.\"\"\"\n",
    "    if len(data) == 0:  # Handle empty subsets\n",
    "        return 0\n",
    "    label_col = data['y']\n",
    "    counts = Counter(label_col)\n",
    "    total = len(label_col)\n",
    "    return -sum((count / total) * log2(count / total) for count in counts.values())\n",
    "\n",
    "def majority_error(data):\n",
    "    \"\"\"Calculate the majority error for a dataset.\"\"\"\n",
    "    if len(data) == 0:  # Handle empty subsets\n",
    "        return 0\n",
    "    label_col = data['y']\n",
    "    counts = Counter(label_col)\n",
    "    majority_class_count = max(counts.values())\n",
    "    total = len(label_col)\n",
    "    return 1 - majority_class_count / total\n",
    "\n",
    "def gini_index(data):\n",
    "    \"\"\"Calculate the Gini index for a dataset.\"\"\"\n",
    "    if len(data) == 0:  # Handle empty subsets\n",
    "        return 0\n",
    "    label_col = data['y']\n",
    "    counts = Counter(label_col)\n",
    "    total = len(label_col)\n",
    "    return 1 - sum((count / total) ** 2 for count in counts.values())\n",
    "\n",
    "# Modify the split_data function to ensure it returns valid DataFrames\n",
    "def split_data(data, attribute, value):\n",
    "    \"\"\"Split the data based on the attribute and value.\"\"\"\n",
    "    return data[data[attribute] == value]\n",
    "\n",
    "# ID3 algorithm implementation to handle both categorical and binary numerical attributes\n",
    "class DecisionTreeID3Modified:\n",
    "    def __init__(self, heuristic, max_depth=None):\n",
    "        self.heuristic = heuristic\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "    \n",
    "    def _get_best_split(self, data, attributes):\n",
    "        base_heuristic_value = self.heuristic(data)\n",
    "        best_gain = 0\n",
    "        best_attribute = None\n",
    "        \n",
    "        for attribute in attributes:\n",
    "            values = data[attribute].unique()\n",
    "            weighted_heuristic = 0\n",
    "            for value in values:\n",
    "                subset = split_data(data, attribute, value)\n",
    "                weight = len(subset) / len(data)\n",
    "                weighted_heuristic += weight * self.heuristic(subset)\n",
    "            \n",
    "            gain = base_heuristic_value - weighted_heuristic\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_attribute = attribute\n",
    "                \n",
    "        return best_attribute\n",
    "\n",
    "    def _build_tree(self, data, attributes, depth):\n",
    "        label_counts = Counter(data['y'])\n",
    "        if len(label_counts) == 1:\n",
    "            return next(iter(label_counts))\n",
    "\n",
    "        if len(attributes) == 0 or (self.max_depth is not None and depth == self.max_depth):\n",
    "            return label_counts.most_common(1)[0][0]\n",
    "\n",
    "        best_attribute = self._get_best_split(data, attributes)\n",
    "        if best_attribute is None:\n",
    "            return label_counts.most_common(1)[0][0]\n",
    "        \n",
    "        tree = {best_attribute: {}}\n",
    "        remaining_attributes = [attr for attr in attributes if attr != best_attribute]\n",
    "        for value in data[best_attribute].unique():\n",
    "            subset = split_data(data, best_attribute, value)\n",
    "            tree[best_attribute][value] = self._build_tree(subset, remaining_attributes, depth + 1)\n",
    "        \n",
    "        return tree\n",
    "\n",
    "    def fit(self, data):\n",
    "        attributes = data.columns[:-1]  # All columns except the label\n",
    "        self.tree = self._build_tree(data, attributes, 0)\n",
    "\n",
    "    def predict_single(self, example, tree):\n",
    "        if not isinstance(tree, dict):\n",
    "            return tree\n",
    "        attribute = next(iter(tree))\n",
    "        value = example[attribute]\n",
    "        subtree = tree[attribute].get(value, None)\n",
    "        if subtree is None:\n",
    "            return None  # In case the value is not found in the training data\n",
    "        return self.predict_single(example, subtree)\n",
    "\n",
    "    def predict(self, data):\n",
    "        return data.apply(lambda row: self.predict_single(row, self.tree), axis=1)\n",
    "\n",
    "# Define heuristics\n",
    "heuristics = {\n",
    "    'information_gain': entropy,\n",
    "    'majority_error': majority_error,\n",
    "    'gini_index': gini_index\n",
    "}\n",
    "\n",
    "# Calculate errors for depths 1 to 16 and different heuristics\n",
    "results = []\n",
    "\n",
    "for heuristic_name, heuristic_function in heuristics.items():\n",
    "    for depth in range(1, 17):\n",
    "        model = DecisionTreeID3Modified(heuristic_function, depth)\n",
    "        model.fit(train_data)\n",
    "        \n",
    "        train_predictions = model.predict(train_data)\n",
    "        test_predictions = model.predict(test_data)\n",
    "        \n",
    "        train_error = np.mean(train_predictions != train_data['y'])\n",
    "        test_error = np.mean(test_predictions != test_data['y'])\n",
    "        \n",
    "        results.append((heuristic_name, depth, train_error, test_error))\n",
    "\n",
    "# Create a DataFrame to display the results for the tree\n",
    "results_df = pd.DataFrame(results, columns=['Heuristic', 'Max Depth', 'Train Error', 'Test Error'])\n",
    "\n",
    "# Display the results\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bfd2c1-933e-4db4-aec6-b009f91524e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
